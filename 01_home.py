# 01_home.py
import streamlit as st
from services.upload_manager import UploadManager
from services.model_manager import ModelManager
from components.ui_upload import render_upload_widget, render_status_documento, render_debug_chunks

st.set_page_config(
    page_title='OrÃ¡culo AcadÃªmico',
    page_icon='ğŸ‘¨ğŸ¾â€ğŸ“',
    layout='wide'
)

# --- CSS: Ajustes finos de layout ---
st.markdown("""
<style>
/* Layout otimizado - previne scroll global mantendo elementos visÃ­veis */
.block-container {
    padding-top: 2rem;  /* Aumentado para evitar corte do tÃ­tulo */
    padding-bottom: 2rem;
}

/* Esconde footer padrÃ£o */
footer {visibility: hidden;}

/* Previne scroll global - permite apenas scroll interno do chat */
section.main > div {
    overflow-y: auto;
    max-height: 100vh;
}

section.main {
    overflow: hidden;
}

/* Ajuste para o container do Streamlit */
.stChatInput {
    padding-bottom: 20px;
}
</style>
""", unsafe_allow_html=True)

# Inicializa managers
if 'upload_manager' not in st.session_state:
    st.session_state['upload_manager'] = UploadManager()
if 'model_manager' not in st.session_state:
    st.session_state['model_manager'] = ModelManager()

# --- Hotfix para instÃ¢ncias obsoletas no session_state ---
if not hasattr(st.session_state['model_manager'].orchestrator, 'create_google_doc_from_structure'):
    del st.session_state['model_manager']
    st.session_state['model_manager'] = ModelManager()
    st.rerun()

upload_manager = st.session_state['upload_manager']
model_manager = st.session_state['model_manager']

# Mapeamento de nomes de agentes para exibiÃ§Ã£o
AGENT_LABELS = {
    'ORCHESTRATOR': 'Maestro (Triagem)',
    'ESTRUTURADOR': 'Agente Estruturador',
    'QA': 'Agente de Pergunta e Resposta'
}

# ===================== SIDEBAR =====================
with st.sidebar:
    st.header('âš™ï¸ ConfiguraÃ§Ãµes')
    render_status_documento()
    st.divider()
    render_upload_widget(upload_manager, model_manager)

    st.divider()
    agente_ativo = st.session_state.get('agente_ativo', 'ORCHESTRATOR')
    label_agente = AGENT_LABELS.get(agente_ativo, agente_ativo)
    st.caption(f"ğŸ¤– **Agente Ativo:** {label_agente}")
    if st.button('ğŸ§¹ Limpar HistÃ³rico', use_container_width=True):

        model_manager.limpar_memoria()
        st.rerun()

# ===================== MAIN =====================
st.title('ğŸ‘¨ğŸ¾â€ğŸ“ OrÃ¡culo AcadÃªmico')

# Info sobre documentos
if upload_manager.total_documentos > 0:
    docs_nomes = [doc.nome for doc in upload_manager.documentos]
    st.caption(f"ğŸ“š Baseado em: {', '.join(docs_nomes)}")

# Tabs
tab_chat, tab_debug = st.tabs(["ğŸ’¬ Chat", "ğŸ” Debug Chunks"])

# ===================== TAB DEBUG =====================
with tab_debug:
    render_debug_chunks()

# ===================== TAB CHAT =====================
with tab_chat:
    if model_manager.chain is None:
        st.info('ğŸ‘ˆ Arraste documento(s) para o painel lateral para comeÃ§ar automaticamente.')
    else:
        usar_rag = st.session_state.get('usar_rag', False)
        
        if usar_rag and st.session_state.get('rag_stats'):
            stats = st.session_state['rag_stats']
            agente_ativo = st.session_state.get('agente_ativo', 'ORCHESTRATOR')
            label_agente = AGENT_LABELS.get(agente_ativo, agente_ativo)
            st.info(f"ğŸ“ **{label_agente}:** Processando solicitaÃ§Ã£o acadÃªmica.")
            st.caption(f"ğŸ§  RAG ativo: {stats.get('total_chunks', 0)} chunks")
        
        # --- EXIBIÃ‡ÃƒO DO LINK DO GOOGLE DOCS ---
        doc_id = st.session_state.get('active_doc_id')
        if doc_id:
            doc_url = f"https://docs.google.com/document/d/{doc_id}/edit"
            st.success(f"ğŸ“ **Documento em ediÃ§Ã£o:** [Abrir no Google Docs]({doc_url})")


        # --- CONTAINER DE SCROLL ---
        chat_container = st.container(height=400, border=False)

        # 1. Renderiza histÃ³rico DENTRO do container de scroll
        with chat_container:
            for msg in model_manager.mensagens:
                with st.chat_message(msg['role']):
                    st.markdown(msg['content'])
            
            # --- LOGICA DE BOTÃ•ES DE FEEDBACK (DENTRO DO SCROLL) ---
            if st.session_state.get('agente_ativo') == 'AGUARDANDO_APROVACAO':
                st.info("ğŸ’¡ **Dica:** VocÃª pode aprovar a estrutura acima ou solicitar ajustes especÃ­ficos.")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("âœ… Aprovar Estrutura", use_container_width=True, key="btn_aprovar"):
                        model_manager.adicionar_mensagem('human', "Estrutura aprovada!")
                        
                        # Tenta encontrar a Ãºltima proposta de estrutura/anÃ¡lise da IA
                        ultima_resposta = ""
                        for msg in reversed(model_manager.mensagens):
                            if msg['role'] == 'ai':
                                # Se encontrarmos uma mensagem que pareÃ§a ser uma proposta, paramos nela
                                content = msg['content']
                                if "###" in content or "Estrutura" in content or "SugestÃ£o" in content:
                                    ultima_resposta = content
                                    break
                                # Caso contrÃ¡rio, guardamos a Ãºltima mensagem da IA como backup
                                if not ultima_resposta:
                                    ultima_resposta = content
                        
                        # Extrai a estrutura real via LLM se houver resposta anterior
                        if ultima_resposta:
                            with st.spinner("Analisando proposta de estrutura..."):
                                structure = model_manager.orchestrator.extrair_estrutura_da_mensagem(ultima_resposta)
                        else:
                            structure = None
                        
                        if structure and structure.get("secoes"):
                            # Tenta criar o Doc (reutiliza se jÃ¡ existir)
                            doc_id = model_manager.orchestrator.create_google_doc_from_structure(structure)
                            if doc_id:
                                st.success(f"Excelente! O documento foi preparado com {len(structure['secoes'])} seÃ§Ãµes.")
                                st.markdown(f"**Link**: [Clique aqui para abrir](https://docs.google.com/document/d/{doc_id})")
                                st.info("Como deseja prosseguir?")
                            else:
                                st.error("NÃ£o foi possÃ­vel criar o documento no Google Docs. Verifique as credenciais.")
                        else:
                            st.warning("âš ï¸ NÃ£o identifiquei uma proposta de estrutura clara na Ãºltima mensagem. Por favor, peÃ§a para o OrÃ¡culo 'estruturar o documento' primeiro.")
                        
                        st.session_state['agente_ativo'] = 'ORCHESTRATOR'
                        st.rerun()
                        
                with col2:
                    if st.button("âŒ Ajustar Estrutura", use_container_width=True, key="btn_ajustar"):
                        st.warning("âš ï¸ Descreva os ajustes desejados no campo de texto abaixo.")
                        
                with col3:
                    if st.button("ğŸ”„ Ignorar/Mudar de Assunto", use_container_width=True, key="btn_ignorar"):
                        st.session_state['agente_ativo'] = 'ORCHESTRATOR'
                        st.rerun()

# 2. Input do UsuÃ¡rio (NÃ­vel raiz para o Streamlit fixar automaticamente)
if model_manager.chain is not None:
    if prompt := st.chat_input('Fale com o OrÃ¡culo AcadÃªmico'):
        # 1. Triagem Imediata para atualizar a UI
        if st.session_state.get('usar_rag'):
             model_manager.orchestrator.classificar_e_atualizar_estado(prompt)

        # 2. Adiciona ao histÃ³rico e marca para execuÃ§Ã£o reativa
        model_manager.adicionar_mensagem('human', prompt)
        st.session_state['prompt_pendente'] = prompt
        st.rerun()

# 3. ExecuÃ§Ã£o de Prompt Pendente (para garantir que a UI rodou com o novo estado)
if 'prompt_pendente' in st.session_state:
    prompt = st.session_state.pop('prompt_pendente')
    with chat_container:
        with st.chat_message('ai'):
            usar_rag = st.session_state.get('usar_rag', False)
            if usar_rag:
                # O state jÃ¡ mudou, o stream usarÃ¡ o agente certo
                resposta = st.write_stream(model_manager.gerar_resposta_rag(prompt))
            else:
                resposta = st.write_stream(
                    model_manager.chain.stream({
                        'input': prompt,
                        'chat_history': model_manager.get_historico_langchain()
                    })
                )
    
    model_manager.adicionar_mensagem('ai', resposta)
    st.rerun()
